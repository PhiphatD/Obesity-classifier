{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d220b258",
   "metadata": {},
   "source": [
    "# ปัญหาเราเป็น multiclass (1–6)\n",
    "\n",
    "ใช้เมตริกหลัก: \n",
    "    - Macro-F1 (เฉลี่ยทุกคลาสเท่ากัน—กันปัญหาคลาสใหญ่ครอบ)\n",
    "    - Accuracy (ดูรวม ๆ)\n",
    "    - Confusion Matrix (ดูผิด/ถูกรายคลาส)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8a4c1d5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From g:\\BU\\Project\\Ai\\.venv\\Lib\\site-packages\\keras\\src\\backend\\common\\global_state.py:82: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Class percents (%):\\n'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Obesity\n",
       "0    12.88\n",
       "1    13.60\n",
       "2    13.74\n",
       "3    13.74\n",
       "4    16.63\n",
       "5    14.07\n",
       "6    15.35\n",
       "Name: count, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Class weights (ใช้ตอนเทรน): {0: 1.108718487394958, 1: 1.0507715281234444, 2: 1.0399014778325124, 3: 1.0399014778325124, 4: 0.8591778591778592, 5: 1.0153920153920153, 6: 0.9307760141093474}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "tf.keras.backend.clear_session()\n",
    "from tensorflow.keras import layers, Model\n",
    "\n",
    "df = pd.read_csv(\"MOBS_02S_Clean.csv\")\n",
    "y = df[\"Obesity\"].astype(int)\n",
    "\n",
    "# สัดส่วนคลาส\n",
    "cnt = y.value_counts().sort_index()\n",
    "N = len(y); K = cnt.shape[0]\n",
    "display(\"Class percents (%):\\n\", (cnt/N*100).round(2))\n",
    "\n",
    "# class weights: N / (K * n_k)\n",
    "class_weight = {int(k): float(N/(K*v)) for k, v in cnt.items()}  \n",
    "print(\"\\nClass weights (ใช้ตอนเทรน):\", class_weight)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "72ddec6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1 — Stratified split 70/15/15 + class_weight(from train only)\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 15% test โดย stratify\n",
    "train_val_df, test_df = train_test_split(df, test_size=0.15, stratify=df[\"Obesity\"], random_state=42)\n",
    "\n",
    "# จาก train_val แบ่ง val อีก ~15% ของทั้งก้อน (0.1765 * 0.85 ≈ 0.15)\n",
    "train_df, val_df = train_test_split(train_val_df, test_size=0.1765, stratify=train_val_df[\"Obesity\"], random_state=42)\n",
    "\n",
    "# 1) จำนวนแถวต้องเท่ากันเมื่อรวม 3 ชุด\n",
    "assert len(train_df) + len(val_df) + len(test_df) == len(df)\n",
    "\n",
    "# 2) ดัชนีห้ามซ้ำระหว่างชุด (ไม่มีแถวใดรั่วไปมา)\n",
    "assert set(train_df.index).isdisjoint(val_df.index)\n",
    "assert set(train_df.index).isdisjoint(test_df.index)\n",
    "assert set(val_df.index).isdisjoint(test_df.index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "431ce52f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ตรวจรวมจำนวนแถว: 2111 จาก 2111\n",
      "\n",
      "class_weight (จาก TRAIN เท่านั้น): {4: 0.8612244897959184, 6: 0.9295154185022027, 5: 1.0144230769230769, 3: 1.0394088669950738, 2: 1.0394088669950738, 1: 1.0497512437810945, 0: 1.1105263157894736}\n"
     ]
    }
   ],
   "source": [
    "# --- ตรวจความถูกต้องของการแบ่ง ---\n",
    "n_total = len(df)\n",
    "print(\"\\nตรวจรวมจำนวนแถว:\", len(train_df) + len(val_df) + len(test_df), \"จาก\", n_total)\n",
    "assert set(train_df.index).isdisjoint(val_df.index)\n",
    "assert set(train_df.index).isdisjoint(test_df.index)\n",
    "assert set(val_df.index).isdisjoint(test_df.index)\n",
    "\n",
    "# --- คำนวณ class_weight จาก TRAIN เท่านั้น ---\n",
    "N = len(train_df)\n",
    "K = train_df[\"Obesity\"].nunique()\n",
    "cw = {int(k): float(N / (K * v)) for k, v in train_df[\"Obesity\"].value_counts().items()}\n",
    "print(\"\\nclass_weight (จาก TRAIN เท่านั้น):\", cw)\n",
    "\n",
    "# ตัวแปรที่ได้ไว้ใช้ต่อ:\n",
    "# train_df, val_df, test_df, cw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "786a9204",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: กำหนดคอลัมน์ที่ใช้ในโมเดล\n",
    "\n",
    "# 1) ระบุคอลัมน์ (ตามที่เราจัดกลุ่มไว้)\n",
    "NUMERIC_COLS = [\"age_clean\", \"bmi\", \"height_m\", \"weight_kg\"]\n",
    "CATEG_COLS = [\n",
    "    \"gender\", \"overweight_family\", \"consum_cf\", \"consum_vf\", \"consum_daily\",\n",
    "    \"consum_other\", \"smoking\", \"consum_water\", \"cal_monitoring\",\n",
    "    \"phyical_activity\", \"device_usage\", \"consum_alchohol\", \"transportation\"\n",
    "]\n",
    "TARGET = \"Obesity\"\n",
    "\n",
    "# สร้าง Keras Inputs\n",
    "\n",
    "inputs = {}\n",
    "for c in NUMERIC_COLS:\n",
    "    inputs[c] = layers.Input(shape=(1,), name=c, dtype=tf.float32)\n",
    "for c in CATEG_COLS:\n",
    "    inputs[c] = layers.Input(shape=(1,), name=c, dtype=tf.int32)\n",
    "\n",
    "# Numeric: Normalization (adapt จาก train เท่านั้น)\n",
    "encoded_parts = []\n",
    "for c in NUMERIC_COLS:\n",
    "    norm = layers.Normalization(name=f\"{c}_norm\")\n",
    "    norm.adapt(train_df[c].to_numpy().reshape(-1,1))\n",
    "    encoded_parts.append(norm(inputs[c]))\n",
    "\n",
    "# Categorical (int-coded): IntegerLookup -> one-hot (adapt จาก train เท่านั้น)\n",
    "for c in CATEG_COLS:\n",
    "    lk = layers.IntegerLookup(output_mode=\"one_hot\", name=f\"{c}_onehot\")\n",
    "    lk.adapt(train_df[c].to_numpy())\n",
    "    encoded_parts.append(lk(inputs[c]))\n",
    "\n",
    "# รวมเป็นเวกเตอร์ฟีเจอร์\n",
    "features = layers.Concatenate(name=\"features_concat\")(encoded_parts)\n",
    "preprocessor = tf.keras.Model(inputs=inputs, outputs=features, name=\"preprocessor\")\n",
    "\n",
    "# helper แพ็ก Pandas → dict (ไม่แตะ missing)\n",
    "def to_keras_inputs(df):\n",
    "    x = {}\n",
    "    for c in NUMERIC_COLS: x[c] = df[c].to_numpy()\n",
    "    for c in CATEG_COLS:   x[c] = df[c].to_numpy()\n",
    "    return x\n",
    "\n",
    "Xtr, ytr = to_keras_inputs(train_df), train_df[TARGET].to_numpy().astype(\"int32\")\n",
    "Xva, yva = to_keras_inputs(val_df),   val_df[TARGET].to_numpy().astype(\"int32\")\n",
    "Xte, yte = to_keras_inputs(test_df),  test_df[TARGET].to_numpy().astype(\"int32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "547af285",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "\n",
    "n_classes = int(train_df[TARGET].nunique())\n",
    "\n",
    "x = preprocessor(inputs)\n",
    "\n",
    "# block 1\n",
    "x = layers.Dense(128, kernel_initializer=\"he_normal\",\n",
    "                 kernel_regularizer=keras.regularizers.l2(1e-4))(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Activation(\"relu\")(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "\n",
    "# block 2\n",
    "x = layers.Dense(64, kernel_initializer=\"he_normal\",\n",
    "                 kernel_regularizer=keras.regularizers.l2(1e-4))(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Activation(\"relu\")(x)\n",
    "x = layers.Dropout(0.4)(x)\n",
    "\n",
    "x = layers.Dense(32, kernel_initializer=\"he_normal\",\n",
    "                 kernel_regularizer=keras.regularizers.l2(1e-4))(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Activation(\"relu\")(x)\n",
    "x = layers.Dropout(0.3)(x)\n",
    "\n",
    "out = layers.Dense(n_classes, activation=\"softmax\")(x)\n",
    "\n",
    "model = Model(inputs=inputs, outputs=out)\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=1e-1),   # ค่อยๆลด lr ให้เสถียรก่อน\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4644fdf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - accuracy: 0.3595 - loss: 1.7757 - val_accuracy: 0.4164 - val_loss: 16.9332 - learning_rate: 0.1000\n",
      "Epoch 2/500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.5782 - loss: 1.2562 - val_accuracy: 0.3943 - val_loss: 42.5332 - learning_rate: 0.1000\n",
      "Epoch 3/500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6608 - loss: 1.1269 - val_accuracy: 0.4164 - val_loss: 36.2950 - learning_rate: 0.1000\n",
      "Epoch 4/500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7014 - loss: 1.0517 - val_accuracy: 0.4290 - val_loss: 32.7568 - learning_rate: 0.1000\n",
      "Epoch 5/500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7265 - loss: 0.9945 - val_accuracy: 0.4259 - val_loss: 24.4785 - learning_rate: 0.1000\n",
      "Epoch 6/500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7508 - loss: 0.9229 - val_accuracy: 0.4322 - val_loss: 19.8430 - learning_rate: 0.1000\n",
      "Epoch 7/500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7590 - loss: 0.8980 - val_accuracy: 0.4511 - val_loss: 16.1868 - learning_rate: 0.1000\n",
      "Epoch 8/500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7698 - loss: 0.8336 - val_accuracy: 0.4511 - val_loss: 13.4109 - learning_rate: 0.1000\n",
      "Epoch 9/500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7718 - loss: 0.8502 - val_accuracy: 0.4700 - val_loss: 9.2764 - learning_rate: 0.1000\n",
      "Epoch 10/500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7393 - loss: 0.8752 - val_accuracy: 0.4984 - val_loss: 7.7385 - learning_rate: 0.1000\n",
      "Epoch 11/500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7820 - loss: 0.7974 - val_accuracy: 0.4858 - val_loss: 6.8439 - learning_rate: 0.1000\n",
      "Epoch 12/500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7651 - loss: 0.8179 - val_accuracy: 0.5457 - val_loss: 3.9611 - learning_rate: 0.1000\n",
      "Epoch 13/500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7996 - loss: 0.7561 - val_accuracy: 0.5079 - val_loss: 5.7913 - learning_rate: 0.1000\n",
      "Epoch 14/500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7630 - loss: 0.7711 - val_accuracy: 0.5300 - val_loss: 4.2011 - learning_rate: 0.1000\n",
      "Epoch 15/500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7854 - loss: 0.7276 - val_accuracy: 0.5237 - val_loss: 3.0606 - learning_rate: 0.1000\n",
      "Epoch 16/500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8145 - loss: 0.6846 - val_accuracy: 0.5552 - val_loss: 3.6226 - learning_rate: 0.1000\n",
      "Epoch 17/500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8097 - loss: 0.7109 - val_accuracy: 0.5710 - val_loss: 2.2581 - learning_rate: 0.1000\n",
      "Epoch 18/500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8016 - loss: 0.6935 - val_accuracy: 0.5268 - val_loss: 2.7627 - learning_rate: 0.1000\n",
      "Epoch 19/500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8064 - loss: 0.7351 - val_accuracy: 0.5268 - val_loss: 2.3199 - learning_rate: 0.1000\n",
      "Epoch 20/500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7739 - loss: 0.8012 - val_accuracy: 0.5110 - val_loss: 2.6394 - learning_rate: 0.1000\n",
      "Epoch 21/500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7976 - loss: 0.7544 - val_accuracy: 0.5268 - val_loss: 2.1230 - learning_rate: 0.1000\n",
      "Epoch 22/500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7820 - loss: 0.7616 - val_accuracy: 0.5741 - val_loss: 1.5836 - learning_rate: 0.1000\n",
      "Epoch 23/500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8145 - loss: 0.7101 - val_accuracy: 0.5521 - val_loss: 1.8055 - learning_rate: 0.1000\n",
      "Epoch 24/500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8050 - loss: 0.7322 - val_accuracy: 0.5678 - val_loss: 1.7205 - learning_rate: 0.1000\n",
      "Epoch 25/500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8436 - loss: 0.6598 - val_accuracy: 0.5994 - val_loss: 1.7098 - learning_rate: 0.1000\n",
      "Epoch 26/500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8158 - loss: 0.7240 - val_accuracy: 0.6372 - val_loss: 1.4806 - learning_rate: 0.1000\n",
      "Epoch 27/500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8226 - loss: 0.6913 - val_accuracy: 0.6562 - val_loss: 1.3368 - learning_rate: 0.1000\n",
      "Epoch 28/500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8111 - loss: 0.7232 - val_accuracy: 0.6940 - val_loss: 1.6015 - learning_rate: 0.1000\n",
      "Epoch 29/500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8287 - loss: 0.6947 - val_accuracy: 0.6656 - val_loss: 1.2131 - learning_rate: 0.1000\n",
      "Epoch 30/500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8152 - loss: 0.6917 - val_accuracy: 0.6688 - val_loss: 1.0868 - learning_rate: 0.1000\n",
      "Epoch 31/500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8152 - loss: 0.6949 - val_accuracy: 0.6309 - val_loss: 1.5114 - learning_rate: 0.1000\n",
      "Epoch 32/500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8104 - loss: 0.7230 - val_accuracy: 0.6404 - val_loss: 1.2952 - learning_rate: 0.1000\n",
      "Epoch 33/500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8192 - loss: 0.7614 - val_accuracy: 0.6909 - val_loss: 1.0405 - learning_rate: 0.1000\n",
      "Epoch 34/500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8301 - loss: 0.7015 - val_accuracy: 0.7098 - val_loss: 0.9024 - learning_rate: 0.0100\n",
      "Epoch 35/500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8334 - loss: 0.6716 - val_accuracy: 0.7224 - val_loss: 0.8177 - learning_rate: 0.0100\n",
      "Epoch 36/500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8761 - loss: 0.6294 - val_accuracy: 0.7603 - val_loss: 0.7417 - learning_rate: 0.0100\n",
      "Epoch 37/500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8646 - loss: 0.6112 - val_accuracy: 0.7823 - val_loss: 0.6901 - learning_rate: 0.0100\n",
      "Epoch 38/500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8714 - loss: 0.6092 - val_accuracy: 0.8360 - val_loss: 0.6272 - learning_rate: 0.0100\n",
      "Epoch 39/500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8639 - loss: 0.5999 - val_accuracy: 0.8675 - val_loss: 0.5675 - learning_rate: 0.0100\n",
      "Epoch 40/500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8761 - loss: 0.5737 - val_accuracy: 0.8896 - val_loss: 0.5254 - learning_rate: 0.0100\n",
      "Epoch 41/500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8957 - loss: 0.5240 - val_accuracy: 0.8959 - val_loss: 0.5060 - learning_rate: 0.0100\n",
      "Epoch 42/500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8856 - loss: 0.5227 - val_accuracy: 0.9117 - val_loss: 0.4890 - learning_rate: 0.0100\n",
      "Epoch 43/500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8930 - loss: 0.5260 - val_accuracy: 0.9274 - val_loss: 0.4454 - learning_rate: 0.0100\n",
      "Epoch 44/500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9086 - loss: 0.4881 - val_accuracy: 0.9401 - val_loss: 0.4203 - learning_rate: 0.0100\n",
      "Epoch 45/500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9100 - loss: 0.4805 - val_accuracy: 0.9369 - val_loss: 0.4083 - learning_rate: 0.0100\n",
      "Epoch 46/500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9005 - loss: 0.4958 - val_accuracy: 0.9369 - val_loss: 0.3981 - learning_rate: 0.0100\n",
      "Epoch 47/500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9032 - loss: 0.4535 - val_accuracy: 0.9401 - val_loss: 0.3865 - learning_rate: 0.0100\n",
      "Epoch 48/500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9045 - loss: 0.4827 - val_accuracy: 0.9432 - val_loss: 0.3780 - learning_rate: 0.0100\n",
      "Epoch 49/500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9127 - loss: 0.4516 - val_accuracy: 0.9401 - val_loss: 0.3758 - learning_rate: 0.0100\n",
      "Epoch 50/500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9188 - loss: 0.4456 - val_accuracy: 0.9369 - val_loss: 0.3769 - learning_rate: 0.0100\n",
      "Epoch 51/500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9201 - loss: 0.4158 - val_accuracy: 0.9401 - val_loss: 0.3668 - learning_rate: 0.0100\n",
      "Epoch 52/500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9066 - loss: 0.4653 - val_accuracy: 0.9432 - val_loss: 0.3593 - learning_rate: 0.0100\n",
      "Epoch 53/500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8984 - loss: 0.4592 - val_accuracy: 0.9338 - val_loss: 0.3684 - learning_rate: 0.0100\n",
      "Epoch 54/500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9221 - loss: 0.4164 - val_accuracy: 0.9338 - val_loss: 0.3651 - learning_rate: 1.0000e-03\n",
      "Epoch 55/500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9215 - loss: 0.4061 - val_accuracy: 0.9369 - val_loss: 0.3616 - learning_rate: 1.0000e-03\n",
      "Epoch 56/500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9079 - loss: 0.4399 - val_accuracy: 0.9432 - val_loss: 0.3578 - learning_rate: 1.0000e-03\n",
      "Epoch 57/500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9174 - loss: 0.4220 - val_accuracy: 0.9432 - val_loss: 0.3552 - learning_rate: 1.0000e-03\n",
      "Epoch 58/500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9127 - loss: 0.4304 - val_accuracy: 0.9432 - val_loss: 0.3515 - learning_rate: 1.0000e-03\n",
      "Epoch 59/500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9100 - loss: 0.4251 - val_accuracy: 0.9432 - val_loss: 0.3486 - learning_rate: 1.0000e-04\n",
      "Epoch 60/500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9188 - loss: 0.4149 - val_accuracy: 0.9464 - val_loss: 0.3458 - learning_rate: 1.0000e-04\n",
      "Epoch 61/500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9181 - loss: 0.4305 - val_accuracy: 0.9464 - val_loss: 0.3433 - learning_rate: 1.0000e-04\n",
      "Epoch 62/500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9215 - loss: 0.4054 - val_accuracy: 0.9464 - val_loss: 0.3412 - learning_rate: 1.0000e-04\n",
      "Epoch 63/500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9140 - loss: 0.4272 - val_accuracy: 0.9464 - val_loss: 0.3391 - learning_rate: 1.0000e-04\n",
      "Epoch 64/500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9100 - loss: 0.4261 - val_accuracy: 0.9464 - val_loss: 0.3372 - learning_rate: 1.0000e-04\n",
      "Epoch 65/500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9093 - loss: 0.4496 - val_accuracy: 0.9464 - val_loss: 0.3359 - learning_rate: 1.0000e-04\n",
      "Epoch 66/500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9066 - loss: 0.4431 - val_accuracy: 0.9464 - val_loss: 0.3344 - learning_rate: 1.0000e-04\n",
      "Epoch 67/500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9059 - loss: 0.4310 - val_accuracy: 0.9464 - val_loss: 0.3331 - learning_rate: 1.0000e-04\n",
      "Epoch 68/500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8937 - loss: 0.4692 - val_accuracy: 0.9495 - val_loss: 0.3317 - learning_rate: 1.0000e-04\n",
      "Epoch 69/500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9120 - loss: 0.4591 - val_accuracy: 0.9495 - val_loss: 0.3307 - learning_rate: 1.0000e-04\n",
      "Epoch 70/500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9160 - loss: 0.4087 - val_accuracy: 0.9495 - val_loss: 0.3294 - learning_rate: 1.0000e-04\n",
      "Epoch 71/500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9235 - loss: 0.4079 - val_accuracy: 0.9495 - val_loss: 0.3287 - learning_rate: 1.0000e-04\n",
      "Epoch 72/500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9188 - loss: 0.4151 - val_accuracy: 0.9495 - val_loss: 0.3278 - learning_rate: 1.0000e-04\n",
      "Epoch 73/500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9167 - loss: 0.4077 - val_accuracy: 0.9495 - val_loss: 0.3272 - learning_rate: 1.0000e-04\n",
      "Epoch 74/500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9276 - loss: 0.3970 - val_accuracy: 0.9495 - val_loss: 0.3262 - learning_rate: 1.0000e-04\n",
      "Epoch 75/500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9086 - loss: 0.4221 - val_accuracy: 0.9495 - val_loss: 0.3258 - learning_rate: 1.0000e-04\n",
      "Epoch 76/500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9093 - loss: 0.4435 - val_accuracy: 0.9495 - val_loss: 0.3251 - learning_rate: 1.0000e-04\n",
      "Epoch 77/500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9228 - loss: 0.4274 - val_accuracy: 0.9464 - val_loss: 0.3245 - learning_rate: 1.0000e-04\n",
      "Epoch 78/500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9201 - loss: 0.4012 - val_accuracy: 0.9464 - val_loss: 0.3242 - learning_rate: 1.0000e-04\n",
      "Epoch 79/500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9269 - loss: 0.3974 - val_accuracy: 0.9464 - val_loss: 0.3237 - learning_rate: 1.0000e-04\n",
      "Epoch 80/500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9072 - loss: 0.4149 - val_accuracy: 0.9464 - val_loss: 0.3231 - learning_rate: 1.0000e-04\n",
      "Epoch 81/500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9221 - loss: 0.4154 - val_accuracy: 0.9432 - val_loss: 0.3228 - learning_rate: 1.0000e-04\n",
      "Epoch 82/500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9201 - loss: 0.3973 - val_accuracy: 0.9432 - val_loss: 0.3224 - learning_rate: 1.0000e-04\n",
      "Epoch 83/500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9289 - loss: 0.3767 - val_accuracy: 0.9432 - val_loss: 0.3222 - learning_rate: 1.0000e-04\n",
      "Epoch 84/500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8856 - loss: 0.4789 - val_accuracy: 0.9464 - val_loss: 0.3219 - learning_rate: 1.0000e-04\n",
      "Epoch 85/500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9364 - loss: 0.3933 - val_accuracy: 0.9464 - val_loss: 0.3216 - learning_rate: 1.0000e-04\n",
      "Epoch 86/500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9160 - loss: 0.4327 - val_accuracy: 0.9464 - val_loss: 0.3213 - learning_rate: 1.0000e-04\n",
      "Epoch 87/500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9174 - loss: 0.4200 - val_accuracy: 0.9464 - val_loss: 0.3209 - learning_rate: 1.0000e-04\n",
      "Epoch 88/500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9188 - loss: 0.4227 - val_accuracy: 0.9464 - val_loss: 0.3203 - learning_rate: 1.0000e-04\n",
      "Epoch 89/500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9147 - loss: 0.4031 - val_accuracy: 0.9464 - val_loss: 0.3200 - learning_rate: 1.0000e-04\n",
      "Epoch 90/500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9228 - loss: 0.4156 - val_accuracy: 0.9464 - val_loss: 0.3199 - learning_rate: 1.0000e-04\n",
      "Epoch 91/500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9154 - loss: 0.4170 - val_accuracy: 0.9464 - val_loss: 0.3198 - learning_rate: 1.0000e-04\n",
      "Epoch 92/500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9221 - loss: 0.3866 - val_accuracy: 0.9464 - val_loss: 0.3195 - learning_rate: 1.0000e-04\n",
      "Epoch 93/500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9133 - loss: 0.4328 - val_accuracy: 0.9464 - val_loss: 0.3194 - learning_rate: 1.0000e-04\n",
      "Epoch 94/500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9174 - loss: 0.4172 - val_accuracy: 0.9464 - val_loss: 0.3190 - learning_rate: 1.0000e-04\n",
      "Epoch 95/500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9181 - loss: 0.4094 - val_accuracy: 0.9464 - val_loss: 0.3186 - learning_rate: 1.0000e-04\n",
      "Epoch 96/500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9221 - loss: 0.4163 - val_accuracy: 0.9464 - val_loss: 0.3185 - learning_rate: 1.0000e-04\n",
      "Epoch 97/500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9201 - loss: 0.4189 - val_accuracy: 0.9464 - val_loss: 0.3187 - learning_rate: 1.0000e-04\n",
      "Epoch 98/500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9316 - loss: 0.3837 - val_accuracy: 0.9464 - val_loss: 0.3188 - learning_rate: 1.0000e-04\n",
      "Epoch 99/500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9228 - loss: 0.3968 - val_accuracy: 0.9464 - val_loss: 0.3186 - learning_rate: 1.0000e-04\n",
      "Epoch 100/500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9154 - loss: 0.4160 - val_accuracy: 0.9464 - val_loss: 0.3185 - learning_rate: 1.0000e-04\n",
      "Epoch 101/500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9194 - loss: 0.4072 - val_accuracy: 0.9464 - val_loss: 0.3182 - learning_rate: 1.0000e-04\n",
      "Epoch 102/500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9106 - loss: 0.4183 - val_accuracy: 0.9464 - val_loss: 0.3179 - learning_rate: 1.0000e-04\n",
      "Epoch 103/500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9106 - loss: 0.4257 - val_accuracy: 0.9464 - val_loss: 0.3178 - learning_rate: 1.0000e-04\n",
      "Epoch 104/500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9120 - loss: 0.4376 - val_accuracy: 0.9464 - val_loss: 0.3178 - learning_rate: 1.0000e-04\n",
      "Epoch 105/500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9120 - loss: 0.4282 - val_accuracy: 0.9464 - val_loss: 0.3179 - learning_rate: 1.0000e-04\n",
      "Epoch 106/500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9194 - loss: 0.4169 - val_accuracy: 0.9464 - val_loss: 0.3178 - learning_rate: 1.0000e-04\n",
      "Epoch 107/500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9154 - loss: 0.4330 - val_accuracy: 0.9464 - val_loss: 0.3176 - learning_rate: 1.0000e-04\n",
      "Epoch 108/500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9269 - loss: 0.4056 - val_accuracy: 0.9464 - val_loss: 0.3177 - learning_rate: 1.0000e-04\n",
      "Epoch 109/500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9154 - loss: 0.4111 - val_accuracy: 0.9464 - val_loss: 0.3177 - learning_rate: 1.0000e-04\n",
      "Epoch 110/500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9201 - loss: 0.4038 - val_accuracy: 0.9464 - val_loss: 0.3175 - learning_rate: 1.0000e-04\n",
      "Epoch 111/500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9215 - loss: 0.4408 - val_accuracy: 0.9464 - val_loss: 0.3173 - learning_rate: 1.0000e-04\n",
      "Epoch 112/500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9296 - loss: 0.3863 - val_accuracy: 0.9464 - val_loss: 0.3172 - learning_rate: 1.0000e-04\n",
      "Epoch 113/500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9147 - loss: 0.4310 - val_accuracy: 0.9464 - val_loss: 0.3173 - learning_rate: 1.0000e-04\n",
      "Epoch 114/500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9120 - loss: 0.4230 - val_accuracy: 0.9464 - val_loss: 0.3172 - learning_rate: 1.0000e-04\n",
      "Epoch 115/500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9059 - loss: 0.4524 - val_accuracy: 0.9464 - val_loss: 0.3174 - learning_rate: 1.0000e-04\n",
      "Epoch 116/500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9221 - loss: 0.3991 - val_accuracy: 0.9464 - val_loss: 0.3172 - learning_rate: 1.0000e-04\n",
      "Epoch 117/500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9235 - loss: 0.4093 - val_accuracy: 0.9464 - val_loss: 0.3169 - learning_rate: 1.0000e-04\n",
      "Epoch 118/500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9215 - loss: 0.4057 - val_accuracy: 0.9464 - val_loss: 0.3170 - learning_rate: 1.0000e-04\n",
      "Epoch 119/500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9235 - loss: 0.4018 - val_accuracy: 0.9464 - val_loss: 0.3169 - learning_rate: 1.0000e-04\n",
      "Epoch 120/500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9147 - loss: 0.4199 - val_accuracy: 0.9464 - val_loss: 0.3166 - learning_rate: 1.0000e-04\n",
      "Epoch 121/500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9086 - loss: 0.4535 - val_accuracy: 0.9464 - val_loss: 0.3165 - learning_rate: 1.0000e-04\n",
      "Epoch 122/500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9113 - loss: 0.4395 - val_accuracy: 0.9464 - val_loss: 0.3163 - learning_rate: 1.0000e-04\n",
      "Epoch 123/500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9330 - loss: 0.3836 - val_accuracy: 0.9464 - val_loss: 0.3163 - learning_rate: 1.0000e-04\n",
      "Epoch 124/500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9174 - loss: 0.4183 - val_accuracy: 0.9464 - val_loss: 0.3162 - learning_rate: 1.0000e-04\n",
      "Epoch 125/500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9262 - loss: 0.4129 - val_accuracy: 0.9464 - val_loss: 0.3159 - learning_rate: 1.0000e-04\n",
      "Epoch 126/500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9059 - loss: 0.4401 - val_accuracy: 0.9464 - val_loss: 0.3160 - learning_rate: 1.0000e-04\n",
      "Epoch 127/500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9309 - loss: 0.4007 - val_accuracy: 0.9464 - val_loss: 0.3162 - learning_rate: 1.0000e-04\n",
      "Epoch 128/500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9215 - loss: 0.3883 - val_accuracy: 0.9464 - val_loss: 0.3163 - learning_rate: 1.0000e-04\n",
      "Epoch 129/500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9350 - loss: 0.3799 - val_accuracy: 0.9464 - val_loss: 0.3162 - learning_rate: 1.0000e-04\n",
      "Epoch 130/500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9282 - loss: 0.3790 - val_accuracy: 0.9464 - val_loss: 0.3160 - learning_rate: 1.0000e-04\n",
      "Epoch 131/500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9072 - loss: 0.4287 - val_accuracy: 0.9464 - val_loss: 0.3159 - learning_rate: 1.0000e-04\n",
      "Epoch 132/500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9242 - loss: 0.4036 - val_accuracy: 0.9464 - val_loss: 0.3156 - learning_rate: 1.0000e-04\n",
      "Epoch 133/500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9106 - loss: 0.4336 - val_accuracy: 0.9464 - val_loss: 0.3155 - learning_rate: 1.0000e-04\n",
      "Epoch 134/500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9215 - loss: 0.4129 - val_accuracy: 0.9464 - val_loss: 0.3158 - learning_rate: 1.0000e-04\n",
      "Epoch 135/500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9147 - loss: 0.4190 - val_accuracy: 0.9464 - val_loss: 0.3158 - learning_rate: 1.0000e-04\n",
      "Epoch 136/500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9154 - loss: 0.4271 - val_accuracy: 0.9464 - val_loss: 0.3158 - learning_rate: 1.0000e-04\n",
      "Epoch 137/500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9228 - loss: 0.4162 - val_accuracy: 0.9464 - val_loss: 0.3159 - learning_rate: 1.0000e-04\n",
      "Epoch 138/500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9181 - loss: 0.4151 - val_accuracy: 0.9464 - val_loss: 0.3157 - learning_rate: 1.0000e-04\n",
      "Epoch 139/500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9188 - loss: 0.4306 - val_accuracy: 0.9464 - val_loss: 0.3154 - learning_rate: 1.0000e-04\n",
      "Epoch 140/500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9262 - loss: 0.4050 - val_accuracy: 0.9464 - val_loss: 0.3154 - learning_rate: 1.0000e-04\n",
      "Epoch 141/500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9316 - loss: 0.3808 - val_accuracy: 0.9464 - val_loss: 0.3154 - learning_rate: 1.0000e-04\n",
      "Epoch 142/500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9174 - loss: 0.4205 - val_accuracy: 0.9464 - val_loss: 0.3152 - learning_rate: 1.0000e-04\n",
      "Epoch 143/500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9336 - loss: 0.3915 - val_accuracy: 0.9464 - val_loss: 0.3151 - learning_rate: 1.0000e-04\n",
      "Epoch 144/500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9242 - loss: 0.4018 - val_accuracy: 0.9464 - val_loss: 0.3150 - learning_rate: 1.0000e-04\n",
      "Epoch 145/500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9201 - loss: 0.4173 - val_accuracy: 0.9464 - val_loss: 0.3149 - learning_rate: 1.0000e-04\n",
      "Epoch 146/500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9248 - loss: 0.4243 - val_accuracy: 0.9464 - val_loss: 0.3149 - learning_rate: 1.0000e-04\n",
      "Epoch 147/500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9127 - loss: 0.4229 - val_accuracy: 0.9464 - val_loss: 0.3150 - learning_rate: 1.0000e-04\n",
      "Epoch 148/500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9343 - loss: 0.3903 - val_accuracy: 0.9464 - val_loss: 0.3147 - learning_rate: 1.0000e-04\n",
      "Epoch 149/500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9350 - loss: 0.3872 - val_accuracy: 0.9464 - val_loss: 0.3149 - learning_rate: 1.0000e-04\n",
      "Epoch 150/500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9262 - loss: 0.3931 - val_accuracy: 0.9464 - val_loss: 0.3148 - learning_rate: 1.0000e-04\n",
      "Epoch 151/500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9242 - loss: 0.4231 - val_accuracy: 0.9464 - val_loss: 0.3145 - learning_rate: 1.0000e-04\n",
      "Epoch 152/500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9228 - loss: 0.4228 - val_accuracy: 0.9464 - val_loss: 0.3144 - learning_rate: 1.0000e-04\n",
      "Epoch 153/500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9140 - loss: 0.4228 - val_accuracy: 0.9464 - val_loss: 0.3143 - learning_rate: 1.0000e-04\n",
      "Epoch 154/500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9276 - loss: 0.3842 - val_accuracy: 0.9464 - val_loss: 0.3142 - learning_rate: 1.0000e-04\n",
      "Epoch 155/500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9086 - loss: 0.4268 - val_accuracy: 0.9464 - val_loss: 0.3138 - learning_rate: 1.0000e-04\n",
      "Epoch 156/500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9269 - loss: 0.4023 - val_accuracy: 0.9464 - val_loss: 0.3138 - learning_rate: 1.0000e-04\n",
      "Epoch 157/500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9316 - loss: 0.3961 - val_accuracy: 0.9464 - val_loss: 0.3138 - learning_rate: 1.0000e-04\n",
      "Epoch 158/500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9215 - loss: 0.4082 - val_accuracy: 0.9464 - val_loss: 0.3138 - learning_rate: 1.0000e-04\n",
      "Epoch 159/500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9235 - loss: 0.4062 - val_accuracy: 0.9464 - val_loss: 0.3141 - learning_rate: 1.0000e-04\n",
      "Epoch 160/500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9303 - loss: 0.3907 - val_accuracy: 0.9464 - val_loss: 0.3140 - learning_rate: 1.0000e-04\n",
      "Epoch 161/500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9208 - loss: 0.4016 - val_accuracy: 0.9464 - val_loss: 0.3142 - learning_rate: 1.0000e-04\n",
      "Epoch 162/500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9194 - loss: 0.3913 - val_accuracy: 0.9464 - val_loss: 0.3141 - learning_rate: 1.0000e-04\n",
      "Epoch 163/500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9255 - loss: 0.3963 - val_accuracy: 0.9464 - val_loss: 0.3140 - learning_rate: 1.0000e-04\n",
      "Epoch 164/500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9242 - loss: 0.3895 - val_accuracy: 0.9464 - val_loss: 0.3143 - learning_rate: 1.0000e-04\n",
      "Epoch 165/500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9221 - loss: 0.4010 - val_accuracy: 0.9464 - val_loss: 0.3145 - learning_rate: 1.0000e-04\n",
      "Epoch 166/500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9262 - loss: 0.4030 - val_accuracy: 0.9464 - val_loss: 0.3142 - learning_rate: 1.0000e-04\n",
      "Epoch 167/500\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9269 - loss: 0.3889 - val_accuracy: 0.9464 - val_loss: 0.3143 - learning_rate: 1.0000e-04\n"
     ]
    }
   ],
   "source": [
    "callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping(patience=10, monitor=\"val_loss\",restore_best_weights=True),\n",
    "    tf.keras.callbacks.ReduceLROnPlateau(monitor=\"val_accuracy\", factor=0.1, patience=5, min_lr=1e-4 )\n",
    "]\n",
    "\n",
    "base_cw = {4: 0.8612244897959184, \n",
    "           6: 0.9295154185022027, \n",
    "           5: 1.0144230769230769, \n",
    "           3: 1.0394088669950738, \n",
    "           2: 1.0394088669950738, \n",
    "           1: 1.0497512437810945, \n",
    "           0: 1.1105263157894736}\n",
    "\n",
    "\n",
    "history = model.fit(\n",
    "    Xtr, ytr,\n",
    "    validation_data=(Xva, yva),\n",
    "    epochs=500,\n",
    "    batch_size=256,\n",
    "    class_weight=base_cw,     \n",
    "    callbacks=callbacks\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b797ac72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VAL: [0.31378576159477234, 0.9463722109794617]\n",
      "TEST: [0.39927423000335693, 0.9526813626289368]\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 167ms/step\n",
      "[[40  1  0  0  0  0  0]\n",
      " [ 2 38  3  0  0  0  0]\n",
      " [ 0  3 37  3  0  0  0]\n",
      " [ 0  0  0 43  0  0  0]\n",
      " [ 0  0  0  0 53  0  0]\n",
      " [ 0  0  0  0  0 44  1]\n",
      " [ 0  0  0  0  0  2 47]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9524    0.9756    0.9639        41\n",
      "           1     0.9048    0.8837    0.8941        43\n",
      "           2     0.9250    0.8605    0.8916        43\n",
      "           3     0.9348    1.0000    0.9663        43\n",
      "           4     1.0000    1.0000    1.0000        53\n",
      "           5     0.9565    0.9778    0.9670        45\n",
      "           6     0.9792    0.9592    0.9691        49\n",
      "\n",
      "    accuracy                         0.9527       317\n",
      "   macro avg     0.9504    0.9510    0.9503       317\n",
      "weighted avg     0.9525    0.9527    0.9522       317\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"VAL:\", model.evaluate(Xva, yva, verbose=0))\n",
    "print(\"TEST:\", model.evaluate(Xte, yte, verbose=0))\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "pred = model.predict(Xte, batch_size=256).argmax(axis=1)\n",
    "print(confusion_matrix(yte, pred))\n",
    "print(classification_report(yte, pred, digits=4))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
